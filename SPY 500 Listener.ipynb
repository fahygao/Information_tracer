{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c3531c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "from pprint import pprint\n",
    "import json\n",
    "import os\n",
    "import pandas as pd \n",
    "import bs4 as bs\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "SUBMIT_URL = 'https://informationtracer.com/submit'\n",
    "STATUS_URL = 'https://informationtracer.com/status'\n",
    "RESULT_URL = 'https://informationtracer.com/result'\n",
    "\n",
    "\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    return score\n",
    "# STEP 1: submit a search query, and get id_hash256 (a unique identifier)\n",
    "def step_1_submit(query, token, start_date, end_date):\n",
    "    id_hash256 = None\n",
    "    try:\n",
    "        response = requests.post(SUBMIT_URL, \n",
    "                             timeout=10,\n",
    "                             json={'query': query, \n",
    "                                   'token': token,\n",
    "                                   'start_date': start_date,\n",
    "                                    'end_date': end_date,\n",
    "                                    'twitter_only': \"true\"\n",
    "                                   }                                   \n",
    "                            )\n",
    "        if 'id_hash256' in response.json():\n",
    "            id_hash256 = response.json()['id_hash256']\n",
    "        else:\n",
    "            print(\"Submission failed!\")\n",
    "            print(response.json())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Submission failed!\")\n",
    "        print(e)\n",
    "    \n",
    "    return id_hash256\n",
    "        \n",
    "\n",
    "# STEP 2: periodically check status, and get partial results (first 5 tweets)\n",
    "def step_2_check_status(id_hash256, token):\n",
    "    task_status = None\n",
    "    MAX_ROUND = 40\n",
    "    current_round = 0\n",
    "    include_partial_results = 1\n",
    "\n",
    "    while task_status != 'finished' and  current_round < MAX_ROUND:            \n",
    "        current_round += 1\n",
    "#         print(current_round)\n",
    "        try:\n",
    "            full_url = '{}?id_hash256={}&token={}&include_partial_results={}'.format(\n",
    "                STATUS_URL, id_hash256, token, include_partial_results\n",
    "                )\n",
    "            response = requests.get(full_url, timeout=10).json()            \n",
    "#             print(response)\n",
    "            if 'status' in response:\n",
    "                # NOTE: can render status_percentage, status_text on the UI\n",
    "                task_status = response['status']\n",
    "                status = response['status']\n",
    "                status_percentage = response['status_percentage']\n",
    "                status_text = response['status_text']\n",
    "                tweet_preview = response.get('tweet_preview', None)\n",
    "#                 if tweet_preview:\n",
    "                    # NOTE: can render tweet_preview on the UI            \n",
    "#                     print('received {} partial tweets'.format(len(tweet_preview)))\n",
    "                    # TO save bandwidth, we can tell the API not to return partial results\n",
    "#                     include_partial_results = 0\n",
    "\n",
    "                if status != 'finished':\n",
    "                    time.sleep(6)\n",
    "                else:\n",
    "                    return 'finished'\n",
    "\n",
    "            else:\n",
    "                print('status is not in response')\n",
    "                pprint(response)\n",
    "                return 'failed'\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Exception when checking job status!')\n",
    "            print(e)\n",
    "\n",
    "    return 'timeout'\n",
    "\n",
    "\n",
    "# STEP 3: get full results\n",
    "def step_3_get_result(id_hash256, token):\n",
    "    try:\n",
    "        response = requests.get('{}?token={}&id_hash256={}'.format(RESULT_URL, token, id_hash256), timeout=10)\n",
    "#         pprint(response.json().keys())\n",
    "#         pprint(response.json())\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return []\n",
    "\n",
    "def step_b1_loadTicker():\n",
    "    try: \n",
    "        resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "        soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "        table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "        table.findAll('tr')[1:][0].findAll('td')[1].text\n",
    "    except: \n",
    "        print(\"cannot get the table from Wiki!\")\n",
    "    tickers = []\n",
    "    companies = []\n",
    "    dc = {}\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        company = row.findAll('td')[1].text\n",
    "        tickers.append(ticker)\n",
    "        companies.append(company)\n",
    "        dc[ticker.replace('\\n', '').replace('.', '-')] = company\n",
    "    tickers = [s.replace('\\n', '').replace('.', '-') for s in tickers]\n",
    "    start =  datetime.datetime(2023, 12, 1) - timedelta(days = 7)\n",
    "    end = datetime.datetime(2023, 12, 1)\n",
    "    data = yf.download(tickers, start=start, end=end)\n",
    "    df_stock = data.stack().reset_index().rename(index=str, columns={\"level_1\": \"Symbol\"}).sort_values(['Symbol','Date'])\n",
    "#     df_stock.set_index('Date', inplace=True)\n",
    "    listCompany = [dc[c] for c in df_stock['Symbol']]\n",
    "    df_stock['company'] = listCompany\n",
    "    return df_stock.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "39ca1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that if there is a buy signal, we buy 1 share;\n",
    "# if there is a sell signal, we sell 1 share; \n",
    "# if there is a buy and a sell then we realize the pnl, else we take the last day as the day to exit and calculate the pnl \n",
    "\n",
    "#get the implied vols!! I do not know how \n",
    "def calculate_total_pnl(df_stock, n):\n",
    "    pnl = 0 \n",
    "    stock_pnl = []\n",
    "    stock_names = []\n",
    "    len_tweets = []\n",
    "\n",
    "\n",
    "    for i in range(0,len(df_stock['Symbol']),n): \n",
    "#         print(\"Symbol\", df_stock['Symbol'][i])\n",
    "        symbol = df_stock['Symbol'][i]\n",
    "        temp_hold = 0\n",
    "        long = False\n",
    "        short = False\n",
    "        total_pnl = 0 \n",
    "        total_t = 0\n",
    "        num = 0 \n",
    "        num_s = 0 \n",
    "        for j in range(n):\n",
    "\n",
    "#             print(df_stock['Symbol'][i+j], num)\n",
    "            try:\n",
    "                num_tw = len(df_stock['Posts_t'][i+j][1:-1].split(\"},\"))\n",
    "            except:\n",
    "                print(df_stock['Symbol'][i], df_stock['Posts_t'][i+j])\n",
    "                num_tw = 0 \n",
    "            if num_tw >= 1 and len(df_stock['Posts_t'][i+j][1:-1].split(\"},\")[0])>0:\n",
    "                total_t +=num_tw\n",
    "            else:\n",
    "                total_t += 0\n",
    "#             total_t += len(df_stock['Posts_t'][i][1:-1].split(\"},\"))\n",
    "#             if symbol != df_stock['Symbol'][i+j]:\n",
    "#                 print(i, df_stock['Symbol'][i+j])\n",
    "    #         print(\"j\",j)\n",
    "    #         print(df_stock['Symbol'][i+j], \"Vader:\",df_stock['Sentiment_Vader'][i+j])\n",
    "            if df_stock['Sentiment_Vader'][i+j] < 0.01 and df_stock['Sentiment_Vader'][i+j] > -0.05:\n",
    "    #             print('pass')\n",
    "\n",
    "    #                 print('short: buy to cover on Friday!', 'Entry price', temp_hold, 'Exit price',df_stock['Adj Close'][i+j])\n",
    "                pass\n",
    "            else:\n",
    "    #             print(df_stock['Sentiment_Vader'][i+j]) \n",
    "                if df_stock['Sentiment_Vader'][i+j] >= 0.05:\n",
    "                    # no position\n",
    "                    if not long and not short:  # the first buy\n",
    "#                         print(\"buy signal and first entry\")\n",
    "                        temp_hold = df_stock['Adj Close'][i+j]\n",
    "#                         print(\"Stock:\",df_stock['Symbol'][i+j], \"price\",temp_hold)\n",
    "                        num+=1\n",
    "                        long = True\n",
    "                    # have a short position and close the short position\n",
    "                    elif short: \n",
    "                        total_pnl += temp_hold + df_stock['Adj Close'][i+j]\n",
    "#                         if symbol=='MRNA':\n",
    "#                             print(\"total_pnl\", total_pnl,temp_hold/num_s,df_stock['Adj Close'][i+j],num_s)\n",
    "                        short = False\n",
    "                        num_s = 0 \n",
    "                    elif long and not short: \n",
    "                        num+=1\n",
    "                        \n",
    "                        temp_hold += df_stock['Adj Close'][i+j]\n",
    "#                         print(\"long again with price in avg: \",temp_hold//num, 'Times of longs #', num)\n",
    "                        \n",
    "                elif df_stock['Sentiment_Vader'][i+j] <= -0.05:\n",
    "                    # have a long position and close the long position \n",
    "                    if long and not short: \n",
    "#                         print(\"sell signal and exit\")\n",
    "                        total_pnl += df_stock['Adj Close'][i+j] -  (temp_hold/num)\n",
    "                        long = False\n",
    "                        num = 0 \n",
    "                    # do not have long or short position\n",
    "                    elif not long and not short: \n",
    "                        temp_hold = - df_stock['Adj Close'][i+j]\n",
    "                        short = True\n",
    "                        num_s = 1\n",
    "    #                 # do not have a long position and already short a stock\n",
    "                    elif not long and short: \n",
    "#                         print(\"short again\")\n",
    "                        temp_hold = (- df_stock['Adj Close'][i+j]+ temp_hold)/(num_s+1)\n",
    "                        num_s +=1\n",
    "#             if symbol=='MRNA':\n",
    "#                 print('MRNA',df_stock['Sentiment_Vader'][i+j],total_pnl,long,short,temp_hold)\n",
    "    #             print(j)\n",
    "            if long and not short and j == n-1: \n",
    "                total_pnl += df_stock['Adj Close'][i+j] - (temp_hold/num)\n",
    "    #             print(\"Stock:\",df_stock['Symbol'][i+j] ,'long: sell on Friday!', 'Entry price', temp_hold,\n",
    "    #                   'Exit price',df_stock['Adj Close'][i+j], \"Total profit:\",df_stock['Adj Close'][i+j] - temp_hold  )\n",
    "            elif short and not long and j == n-1: \n",
    "                total_pnl += (df_stock['Adj Close'][i+j] + temp_hold)/(num_s+1)\n",
    "        stock_names.append(df_stock['Symbol'][i+j])\n",
    "        len_tweets.append(total_t)\n",
    "            # long position but no sell signal\n",
    "    #         print(j)\n",
    "#         print(\"long:\", long, \"short\", short )\n",
    "#         print(pnl)\n",
    "        pnl += total_pnl\n",
    "        stock_pnl.append(total_pnl)\n",
    "        stock = sorted(set(df_stock['Symbol']))\n",
    "        df_pnl = pd.DataFrame({'Symbol': stock_names, 'PNL_VADER':stock_pnl, 'Len_Ts':len_tweets} )\n",
    "        \n",
    "    return pnl, df_pnl\n",
    "\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "c3c31fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/herculesgao/Desktop/Information_Tracer\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c7ecf95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/herculesgao/Desktop/Information_Tracer/week2\n"
     ]
    }
   ],
   "source": [
    "cd week2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "36da27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY12_04_12_08_VADERPNL.csv  SPY500_stock_2023_12_08.csv\r\n",
      "SPY500_stock_2023_12_04.csv  SPY500_stock_week1.csv\r\n",
      "SPY500_stock_2023_12_05.csv  SPYweek1_VADERPNL.csv\r\n",
      "SPY500_stock_2023_12_06.csv  \u001b[34mSummary\u001b[m\u001b[m/\r\n",
      "SPY500_stock_2023_12_07.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "3e713174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of days 5\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "glued_data = pd.DataFrame()\n",
    "n = 0 \n",
    "for file_name in glob.glob('SPY500_stock_*12*.csv'):\n",
    "    n +=1\n",
    "    x = pd.read_csv(file_name, low_memory=False)\n",
    "    glued_data = pd.concat([glued_data,x],axis=0)\n",
    "print(\"number of days\", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "bcac2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "glued_data.sort_values(['Symbol', 'Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5d3e06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "glued_data = glued_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "464ebf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i in glued_data['Symbol']:\n",
    "    if i not in dic: \n",
    "        dic[i] = 1\n",
    "    else: \n",
    "        dic[i] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "50ef24e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in dic if dic[i]!=n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "1f1b94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if [i for i in dic if dic[i]!=n]:\n",
    "\n",
    "    glued_data = glued_data[glued_data['Symbol']!=[i for i in dic if dic[i]!=n][0]].reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f94ef7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glued_data['Sentiment_Vader'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9adc9d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WM nan\n",
      "WMB nan\n"
     ]
    }
   ],
   "source": [
    "pnl, df_pnl = calculate_total_pnl(glued_data,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "aaaa7972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267.4704502900436"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4f17fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pnl.to_csv(\"SPYweek2_VADERPNL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d53029",
   "metadata": {},
   "source": [
    "I cannot retrieve the historical implied volatility from SPY. Next week, I am going to add implied vol column every day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "011b3109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we could not find the sector for the following! ALK\n",
      "Please give a sector for the ticker below!Industrials\n",
      "we could not find the sector for the following! SEDG\n",
      "Please give a sector for the ticker below!Information Technology\n",
      "we could not find the sector for the following! SEE\n",
      "Please give a sector for the ticker below!Consumer Discretionary\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "table.findAll('tr')[1:][0].findAll('td')[1].text\n",
    "tickers = []\n",
    "sectors = []\n",
    "dc = {}\n",
    "# print(row.findAll('td')[3].text)\n",
    "for row in table.findAll('tr')[1:]:\n",
    "#     if  row.findAll('td')[0].text.replace('\\n', '') not in list(df_pnl['Symbol']):\n",
    "    ticker = row.findAll('td')[0].text\n",
    "    sector = row.findAll('td')[2].text\n",
    "    dc[ticker.replace('\\n', '').replace('.', '-')] = sector\n",
    "#     dc[ticker.replace('\\n', '')] = company\n",
    "# start =  datetime.datetime(2023, 12, 1) - timedelta(days = 7)\n",
    "# end = datetime.datetime(2023, 12, 1)\n",
    "# data = yf.download(tickers, start=start, end=end)\n",
    "# df_sector = data.stack().reset_index().rename(index=str, columns={\"level_1\": \"Symbol\"}).sort_values(['Symbol','Date'])\n",
    "# #     df_stock.set_index('Date', inplace=True)\n",
    "# Sector = [dc[c] for c in dc]\n",
    "extra_list = []\n",
    "\n",
    "\n",
    "\n",
    "sectors = []\n",
    "for i in df_pnl['Symbol']:\n",
    "    try:\n",
    "#         print(i,dc[i])\n",
    "        sectors.append(dc[i])\n",
    "    except: \n",
    "        print(\"we could not find the sector for the following!\",i)\n",
    "        add_sector = input(\"Please give a sector for the ticker below!\")\n",
    "        extra_list.append((i,add_sector))\n",
    "        sectors.append(add_sector)\n",
    "df_pnl['Sector'] = sectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c16464bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pnl['Sector'] = sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "11e57ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(c, dc[c]) for c in dc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "a0c686c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ALK', 'Industrials'),\n",
       " ('SEDG', 'Information Technology'),\n",
       " ('SEE', 'Consumer Discretionary')]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "8130a261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ALK', 'Industrials')\n",
      "found it!\n",
      "('SEDG', 'Information Technology')\n",
      "('SEE', 'Consumer Discretionary')\n",
      "('ALK', 'Industrials')\n",
      "found it!\n",
      "('SEDG', 'Information Technology')\n",
      "('SEE', 'Consumer Discretionary')\n",
      "('ALK', 'Industrials')\n",
      "found it!\n",
      "('SEDG', 'Information Technology')\n",
      "('SEE', 'Consumer Discretionary')\n",
      "('ALK', 'Industrials')\n",
      "found it!\n",
      "('SEDG', 'Information Technology')\n",
      "('SEE', 'Consumer Discretionary')\n",
      "('ALK', 'Industrials')\n",
      "found it!\n",
      "('SEDG', 'Information Technology')\n",
      "('SEE', 'Consumer Discretionary')\n",
      "('ALK', 'Industrials')\n",
      "('SEDG', 'Information Technology')\n",
      "found it!\n",
      "('SEE', 'Consumer Discretionary')\n",
      "('ALK', 'Industrials')\n",
      "('SEDG', 'Information Technology')\n",
      "found it!\n",
      "('SEE', 'Consumer Discretionary')\n",
      "('ALK', 'Industrials')\n",
      "('SEDG', 'Information Technology')\n",
      "found it!\n",
      "('SEE', 'Consumer Discretionary')\n",
      "('ALK', 'Industrials')\n",
      "('SEDG', 'Information Technology')\n",
      "found it!\n",
      "('SEE', 'Consumer Discretionary')\n",
      "('ALK', 'Industrials')\n",
      "('SEDG', 'Information Technology')\n",
      "found it!\n",
      "('SEE', 'Consumer Discretionary')\n",
      "('ALK', 'Industrials')\n",
      "('SEDG', 'Information Technology')\n",
      "('SEE', 'Consumer Discretionary')\n",
      "found it!\n",
      "('ALK', 'Industrials')\n",
      "('SEDG', 'Information Technology')\n",
      "('SEE', 'Consumer Discretionary')\n",
      "found it!\n",
      "('ALK', 'Industrials')\n",
      "('SEDG', 'Information Technology')\n",
      "('SEE', 'Consumer Discretionary')\n",
      "found it!\n",
      "('ALK', 'Industrials')\n",
      "('SEDG', 'Information Technology')\n",
      "('SEE', 'Consumer Discretionary')\n",
      "found it!\n",
      "('ALK', 'Industrials')\n",
      "('SEDG', 'Information Technology')\n",
      "('SEE', 'Consumer Discretionary')\n",
      "found it!\n"
     ]
    }
   ],
   "source": [
    "sectors = []\n",
    "for i in glued_data['Symbol']:\n",
    "#     print(i,dc[i])\n",
    "    try: \n",
    "        sectors.append(dc[i])\n",
    "    except: \n",
    "        for j in range(len(extra_list)):\n",
    "            print(extra_list[j])\n",
    "            if extra_list[j][0] == i: \n",
    "#                 print(extra_list[j])\n",
    "\n",
    "                sectors.append(extra_list[j][1])\n",
    "                print(\"found it!\")\n",
    "#                 break\n",
    "\n",
    "#             print(\"we could not find the sector for the following!\",i)\n",
    "#             add_sector = input(\"Please give a sector for the ticker below!\")\n",
    "#             sectors.append(add_sector)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f3a4d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "glued_data['Sector'] = sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f0ee7c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pnl.to_csv(\"SPYweek1_VADERPNL.csv\", index=False)\n",
    "glued_data.to_csv('SPY500_stock_week1.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b67099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
